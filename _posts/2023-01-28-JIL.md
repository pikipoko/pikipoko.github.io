---
title: "JIL"
date: 28/01/2022
categories: SWJG
---

## 나만무

나만의 무기 발표가 끝나고 포스터 세션에서 예상했던 것보다 얼굴인식 및 흐린사진 판별 기능에 관심을 많이 가져주셔서 감사했다.  
하지만 몇몇 질문들에서는 얼버무리듯이 답변을 했다.  
듣는 분들도 당연히 그걸 느꼈을 것이고, 면접 때는 프로젝트를 진행하면서 구현한 기능들을 제대로 설명할 수 있어야 겠다는 당연한 사실을 깨달았다.

그래서 오늘, 발표 이전에 했어야 했지만 이제라도 한 번 프로젝트에서 사용한 기능들에 대한 정리를 해보려고 한다.

### 얼굴인식

얼굴인식 관련해서는 AWS Rekognition의 성능이 어떤지에 대한 질문과 face-api와 관련해서 어떤 점이 나은지, AWS Rekognition을 어떻게 사용했는지, 얼굴인식 기술의 원리에 대해서는 어느 정도로 아는지 등의 질문들을 받았다.

#### face-api.js

face-api.js는 얼굴 모델부터 시작해서 얼굴에 대한 특징점도 직접 뽑아내서 사용할 수 있었다.  
즉, 얼굴 인식 및 비교 과정에 대해 개발자가 하나하나 커스터마이징하여 사용할 수 있다는 장점을 가지고 있었다.  
하지만, 큰 문제가 있었다. 바로 일반 얼굴 모델을 사용하면, 사진 한 장을 비교하는 데에 5초 정도 소요되는 문제였다.  
그래서 Tiny 얼굴 모델을 사용했는데, 사진 한 장을 비교하는 데 비교적 짧은 1초 정도 소요되었지만, 정확도가 많이 떨어졌다.  
이 문제를 어떻게 해결할 지 팀 내부적으로 고민을 많이 했다. 프론트적으로 풀어나갈 것인지(로딩 화면, 이미지 업로드 후 업로드 된 이미지 url만 미리 보내주고, 얼굴 분석 작업은 끝나고 나면 프론트로 전달해주자 등등), 백엔드에서 어떻게든 얼굴인식 속도를 높여볼 것인지(face-api.js를 파고파서 최적화를 시켜보자) 등의 얘기를 했다.

#### AWS Rekognition

그러던 와중에 저장 공간을 빌리는 AWS S3처럼, 얼굴 인식 기능을 대신 해주는 서비스 같은 건 없나? 하는 생각이 들었고 눈 앞에 그 서비스가 있었다.  
AWS에서 얼굴 인식 및 비교 연산을 대신 해주는 Rekognition이라는 서비스가 있는 걸 발견하고 홀린 듯이 Rekognition에 대해 알아보기 시작했다.  
관련 자료는 정말 참고 할만한 게 하나도 없어서, AWS 자습서를 뜯어보면서 어떻게 적용시킬 수 있고 어떤 기능을 사용할 수 있는지를 알아나갔다.

일단 우리는, node.js + express로 서버를 구성해서 사용하고 있었고, node.js로 적용할 수 있는 기능은 detectFace와 compareFace였다. 다른 기능들은 사용할 수 없었다.  
detectFace는 사진 한 장을 넣으면 그 사진에 얼굴이 있는지 없는지 판별해서 응답을 보내주었고, compareFace는 sourceImage와 targetImage 이렇게 두 장의 사진을 요청보내면 응답으로 sourceImage에 있는 얼굴이 targetImage에 있는 얼굴들과 얼마나 유사한지를 알려주었다.

face-api.js와 비교해서 속도와 정확도가 어마무시하게 차이가 났다. 분석 한 번에 1초 정도 소요되었는데, 사진 여러 장을 비동기적으로 요청할 수 있었기 때문에 여러 장을 요청 보낼 때 더욱 속도 차이를 체감할 수 있었다(5장의 얼굴 인식 요청 시 2~3초 정도). 또한 S3에 올라간 사진 URL을 사용하여 Rekognition 서비스를 사용하기 때문에 기존에 사용하던 S3를 그대로 사용할 수 있다는 장점도 있었다.

정확도 또한 엄청 좋았는데, 마스크를 쓰고 있거나 옆모습을 분석요청해도 그 사람으로 정확하게 인식해주었고, 흐린 사진또한 상당히 원활하게 인식해주었다.

여러 번 테스트 한뒤 AWS Rekognition으로 틀지 않을 이유가 없다는 것을 알게 되었고, 정들었던 face-api.js를 버리고 AWS Rekognition으로 프로젝트를 이어나가기로 했다.

속도 및 정확도 차이가 많이 나는 이유는 face-api.js를 사용하면 서버에서 직접 얼굴 인식 과정을 거쳐야 하기 때문이라고 생각한다. 성능이 그렇게 좋지 않은 CPU 1개와 GPU가 없는 free-tier 서버로는 여러 장의 얼굴 인식 요청은 서버 성능에 맞지 않는 작업양이기 때문이다. AWS Rekognition은 S3에 업로드된 URL만 요청으로 보내주면 되기 때문에 우리 서버의 성능에 걸맞는 작업이다.

### 흐린사진 판별

흐린사진을 선명한 사진으로 만들어주는 자료들은 굉장히 많았는데, 사진이 흐린지 안흐린지 구분해주는 라이브러리는 찾기 어려웠다.  
흐린사진은 어떻게 판별할 수 있을까.  
흐린사진과 선명한 사진의 차이점은 무엇일까.

내가 찾은 방법은 바로 가장자리를 세는 방법이었다. 여기서 말하는 가장자리는 픽셀값이 변하는 곳, 즉 색이 변하는 곳이다. 그리고 선명한 가장자리란 픽셀값이 급격하게 변하는 곳, 색이 급격하게 변하는 곳이라고 볼 수 있다.

사진에서 선명한 가장자리 개수를 세서 일정 개수를 넘어가면 선명한 사진이고 일정 개수 미만이면 흐린 사진이라는 단순한 방식을 생각해냈다.  
사진에서 가장자리 탐색에 사용되는 메소드인 opencv의 laplacian 연산자를 사용하여 개수를 셌고, 기준치를 적절히 변경하여 흐린 사진을 판별해주는 기능을 구현하였다.  
맞다 별로 좋은 방식이 아니고 당연히 더 좋은 방법이 있지 않을까? 하는 생각이 들겠지만, 나로서는 최선이었다.

#### opencv.js

처음 흐린 사진을 구현하겠다고 마음먹고 자료를 찾아봤을 때는 javascript에서 opencv.js를 사용하면 opencv의 기능들을 다 사용할 수 있다는 자료를 많이 볼 수 있었기에 위 방식으로 구현한 다음 개선하려고 했다.  
하지만 opencv.js를 사용하면서 알게된 점은 웹에서만 사용할 수 있다는 것이었다.. 서버단에서는 사용을 못하고 프론트에서 document로 이미지 파일을 읽어와서 사용해야만 opencv.js를 사용할 수 있었는데, 분명히 서버에서 사용할 수 있는 방법이 있었을 테지만, 구차하게 변명하자면 흐린 사진 판별 기능을 넣자고 결정한 때가 마무리 발표 다음날이었기 때문에 시간이 부족하여 알아보지 못했다. 능력 부족이었다.

여튼 그래서 opencv.js는 맛만 보고 떠나보낼 수 밖에 없었고 테스트용으로 프론트를 만들어보고 이해하느라 하루 반 정도를 날렸다.

#### opencv4nodejs

opencv.js를 사용할 수 없다면 당연히 누군가가 이 불편함을 해소하려고 했겠지하며 알아봤을 때 opencv4nodejs라는 모듈을 만나게 되었다. 이름부터 우리 서버를 위한 모듈이다 하면서 반갑게 사용해보려 했지만, 설치가 되지 않았다. 구글 선생님과 GPT 선생님의 도움으로 opencv를 서버에 깔아서 시도해보게 되었는데, 서버에 깐다는 게 모델을 직접 풀어야 되는 건 줄 알고 c++ 코드를 5시간 동안 실행시켜서 모델을 풀었는데도 opencv4nodejs를 설치할 수 없었고, 왜 그런지 아무리 찾아봐도 조급한 마음에서인지 알 수가 없었다. opencv를 까는 데만 3일 정도를 날려먹은 상태였기 때문에 javascript로 opencv를 사용해서 흐린 사진을 판별하는 기능을 포기할 수 밖에 없었다. 코드와 기능들을 정리하고 발표 준비를 시작해야 했기에.  
그래서 node.js + express로 서버를 구축하고 자식 프로세스로 python에 opencv를 돌려서 laplacian 연산자를 사용해서 흐린 사진을 판별하는 이상하지만 최선이었던 서브 서버를 구성하게 되었다.

---

다 적고 보니 정리는 안되고 구현 과정을 돌이켜 보는 시간이 된 것 같다.

구현하면서 초반에는 하루하루가 큰 산을 넘는 느낌이었는데, 다 구현하고 정리하면서 돌이켜보니 또 그렇게 어렵진 않았던 것 같기도 하고 좀 더 잘 만들 수 있었을 것 같은데 하는 아쉬움이 남는다.  
이제는 취업 준비를 하면서 이런 여러 사람과 하루종일 붙어있으면서 함께 하는 프로젝트를 한 번 더 겪어볼 기회가 있을지 모르겠지만, 기회가 있다면 잘 만들어 보고 싶다.
